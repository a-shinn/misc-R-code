---
title: "L06 Ensemble Models"
subtitle: "Data Science III (STAT 301-3)"
author: "Austin Shinn"
output: 
  html_document:
    toc: true
    toc_float: true
    highlight: "tango"
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Load package(s) ----
library(tidymodels)
library(tidyverse)
library(stacks)

load("model_info/wildfires_final.rda")
load("model_info/wildfires_blend.rda")
load("data/wildfires_split.rda")
wildfires_test <- wildfires_split %>% testing()
```

-------------------------------------

The stacked ensemble model considered 41 candidate models, with 6 retained in the final model. The models used were KNN, radial kernel support vector machines, and linear regression. The highest weighted type was a linear regression model, with a weight of .68154, and the 2nd highest weight was a support vector machine with a weight of .2847. These 2 make up the majority of the weight, with the next 4 being weighted .03 or less (SVM and KNN models).

```{r echo=FALSE, message=FALSE, warning=FALSE}
wildfires_final
```
```{r message=FALSE, warning=FALSE, include=FALSE}
# creating and adding the prediction column
wildfires_fit <- wildfires_test %>%
  bind_cols(predict(wildfires_final, .)) %>%
  select(burned, .pred)

wildfires_fit

wildfires_metric <- metric_set(rmse, rsq)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Evaluate the ensemble model
wildfires_fit %>% 
  wildfires_metric(truth = burned, estimate = .pred)
```

```{r echo=FALSE}
ggplot(data = wildfires_fit, mapping = aes(burned, .pred)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0) +
  geom_smooth() +
  theme_minimal() +
  coord_obs_pred()
```

The ensemble model had an RMSE value of 93.297, and an R^2 of .934. The fit is generally quite accurate, but falls off from a simple linear fit near the higher values of burned.

```{r echo=FALSE, message=FALSE, warning=FALSE}
member_pred <- wildfires_test %>%
  select(burned) %>%
  bind_cols(predict(wildfires_final, wildfires_test, members = TRUE))

# Evaluate each of the individual models
map_dfr(member_pred, rmse, truth = burned, data = member_pred) %>%
  mutate(member = colnames(member_pred))
```

Looking at the final RMSE values for the models, the linear regression model actually had the lowest RMSE, with an RMSE value of 92.258 compared the 93.297 for the ensemble model. The next closest model was a support vector machine model with an RMSE of 97.882. After that the RMSEs increase drastically. So it appears that a simple linear regression model is more effective and should also save more time computationally.

## Github Repo Link

[https://github.com/STAT301III/L06-ensemble-models-shinnsplints](https://github.com/STAT301III/L06-ensemble-models-shinnsplints){target="_blank"}

